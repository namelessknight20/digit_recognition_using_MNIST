{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33c8212-68e9-4fd4-ae77-9284232c0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Torch CUDA: 12.1\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Python:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af209118-06f8-4440-9d2a-ae70668a0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab61e0d2-d269-467c-a7e2-ff0a574ba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2da611-9863-49bd-9adf-a5e6c0428692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46980af9-5793-4fbb-a399-134497ea2999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6a4c6c-47f8-4b99-900e-eb9de523f50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b114bab-b530-44ad-be40-a39a6b2062f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268b453e-a45f-47ae-a302-fb874d37aa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900a89f1-7e8c-480a-a840-78c4a0c494b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efaba2dd-ff24-4e40-827b-fcf32611bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                       batch_size=100,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1),\n",
    "    \n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size=100,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50477fa-dfa3-47e4-b754-782c9cf85679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x17dffbc8340>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x17dffbca650>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad03219-a369-4e76-896d-47bf160f65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\n",
    "        x = x.view(x.size(0), -1)   # safer than (-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x   # ‚ùó NO softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02725c3d-b894-40e4-9a32-b163341c31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(\n",
    "                f\"Train Epoch {epoch} \"\n",
    "                f\"[{batch_idx * len(data)}/{len(loaders['train'].dataset)} \"\n",
    "                f\"({100. * batch_idx / len(loaders['train']):.0f}%)]\\t\"\n",
    "                f\"Loss: {loss.item():.6f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "\n",
    "    print(\n",
    "        f\"\\nTest set: Average loss: {test_loss:.4f}, \"\n",
    "        f\"Accuracy: {correct}/{len(loaders['test'].dataset)} \"\n",
    "        f\"({100. * correct / len(loaders['test'].dataset):.0f}%)\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf01017-8522-4932-9707-e0c4b96f79c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1 [0/60000 (0%)]\tLoss: 2.310929\n",
      "Train Epoch 1 [2000/60000 (3%)]\tLoss: 2.223731\n",
      "Train Epoch 1 [4000/60000 (7%)]\tLoss: 1.789836\n",
      "Train Epoch 1 [6000/60000 (10%)]\tLoss: 1.406598\n",
      "Train Epoch 1 [8000/60000 (13%)]\tLoss: 1.205204\n",
      "Train Epoch 1 [10000/60000 (17%)]\tLoss: 0.827075\n",
      "Train Epoch 1 [12000/60000 (20%)]\tLoss: 0.770804\n",
      "Train Epoch 1 [14000/60000 (23%)]\tLoss: 0.523421\n",
      "Train Epoch 1 [16000/60000 (27%)]\tLoss: 0.662469\n",
      "Train Epoch 1 [18000/60000 (30%)]\tLoss: 0.587049\n",
      "Train Epoch 1 [20000/60000 (33%)]\tLoss: 0.538305\n",
      "Train Epoch 1 [22000/60000 (37%)]\tLoss: 0.533045\n",
      "Train Epoch 1 [24000/60000 (40%)]\tLoss: 0.446538\n",
      "Train Epoch 1 [26000/60000 (43%)]\tLoss: 0.541070\n",
      "Train Epoch 1 [28000/60000 (47%)]\tLoss: 0.642868\n",
      "Train Epoch 1 [30000/60000 (50%)]\tLoss: 0.409828\n",
      "Train Epoch 1 [32000/60000 (53%)]\tLoss: 0.472105\n",
      "Train Epoch 1 [34000/60000 (57%)]\tLoss: 0.524908\n",
      "Train Epoch 1 [36000/60000 (60%)]\tLoss: 0.403435\n",
      "Train Epoch 1 [38000/60000 (63%)]\tLoss: 0.281746\n",
      "Train Epoch 1 [40000/60000 (67%)]\tLoss: 0.468188\n",
      "Train Epoch 1 [42000/60000 (70%)]\tLoss: 0.423109\n",
      "Train Epoch 1 [44000/60000 (73%)]\tLoss: 0.303258\n",
      "Train Epoch 1 [46000/60000 (77%)]\tLoss: 0.327809\n",
      "Train Epoch 1 [48000/60000 (80%)]\tLoss: 0.433224\n",
      "Train Epoch 1 [50000/60000 (83%)]\tLoss: 0.394847\n",
      "Train Epoch 1 [52000/60000 (87%)]\tLoss: 0.452509\n",
      "Train Epoch 1 [54000/60000 (90%)]\tLoss: 0.450924\n",
      "Train Epoch 1 [56000/60000 (93%)]\tLoss: 0.419466\n",
      "Train Epoch 1 [58000/60000 (97%)]\tLoss: 0.236776\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9597/10000 (96%)\n",
      "\n",
      "Train Epoch 2 [0/60000 (0%)]\tLoss: 0.416258\n",
      "Train Epoch 2 [2000/60000 (3%)]\tLoss: 0.416404\n",
      "Train Epoch 2 [4000/60000 (7%)]\tLoss: 0.437841\n",
      "Train Epoch 2 [6000/60000 (10%)]\tLoss: 0.377021\n",
      "Train Epoch 2 [8000/60000 (13%)]\tLoss: 0.342420\n",
      "Train Epoch 2 [10000/60000 (17%)]\tLoss: 0.294495\n",
      "Train Epoch 2 [12000/60000 (20%)]\tLoss: 0.230419\n",
      "Train Epoch 2 [14000/60000 (23%)]\tLoss: 0.386503\n",
      "Train Epoch 2 [16000/60000 (27%)]\tLoss: 0.297974\n",
      "Train Epoch 2 [18000/60000 (30%)]\tLoss: 0.516587\n",
      "Train Epoch 2 [20000/60000 (33%)]\tLoss: 0.216475\n",
      "Train Epoch 2 [22000/60000 (37%)]\tLoss: 0.131487\n",
      "Train Epoch 2 [24000/60000 (40%)]\tLoss: 0.259983\n",
      "Train Epoch 2 [26000/60000 (43%)]\tLoss: 0.201185\n",
      "Train Epoch 2 [28000/60000 (47%)]\tLoss: 0.292132\n",
      "Train Epoch 2 [30000/60000 (50%)]\tLoss: 0.408640\n",
      "Train Epoch 2 [32000/60000 (53%)]\tLoss: 0.226307\n",
      "Train Epoch 2 [34000/60000 (57%)]\tLoss: 0.264552\n",
      "Train Epoch 2 [36000/60000 (60%)]\tLoss: 0.198977\n",
      "Train Epoch 2 [38000/60000 (63%)]\tLoss: 0.316715\n",
      "Train Epoch 2 [40000/60000 (67%)]\tLoss: 0.268452\n",
      "Train Epoch 2 [42000/60000 (70%)]\tLoss: 0.279800\n",
      "Train Epoch 2 [44000/60000 (73%)]\tLoss: 0.289119\n",
      "Train Epoch 2 [46000/60000 (77%)]\tLoss: 0.249054\n",
      "Train Epoch 2 [48000/60000 (80%)]\tLoss: 0.240074\n",
      "Train Epoch 2 [50000/60000 (83%)]\tLoss: 0.243071\n",
      "Train Epoch 2 [52000/60000 (87%)]\tLoss: 0.260591\n",
      "Train Epoch 2 [54000/60000 (90%)]\tLoss: 0.179269\n",
      "Train Epoch 2 [56000/60000 (93%)]\tLoss: 0.149662\n",
      "Train Epoch 2 [58000/60000 (97%)]\tLoss: 0.198478\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9713/10000 (97%)\n",
      "\n",
      "Train Epoch 3 [0/60000 (0%)]\tLoss: 0.309904\n",
      "Train Epoch 3 [2000/60000 (3%)]\tLoss: 0.278248\n",
      "Train Epoch 3 [4000/60000 (7%)]\tLoss: 0.285738\n",
      "Train Epoch 3 [6000/60000 (10%)]\tLoss: 0.250845\n",
      "Train Epoch 3 [8000/60000 (13%)]\tLoss: 0.331133\n",
      "Train Epoch 3 [10000/60000 (17%)]\tLoss: 0.183624\n",
      "Train Epoch 3 [12000/60000 (20%)]\tLoss: 0.232556\n",
      "Train Epoch 3 [14000/60000 (23%)]\tLoss: 0.321083\n",
      "Train Epoch 3 [16000/60000 (27%)]\tLoss: 0.156810\n",
      "Train Epoch 3 [18000/60000 (30%)]\tLoss: 0.315815\n",
      "Train Epoch 3 [20000/60000 (33%)]\tLoss: 0.371232\n",
      "Train Epoch 3 [22000/60000 (37%)]\tLoss: 0.086343\n",
      "Train Epoch 3 [24000/60000 (40%)]\tLoss: 0.223350\n",
      "Train Epoch 3 [26000/60000 (43%)]\tLoss: 0.319854\n",
      "Train Epoch 3 [28000/60000 (47%)]\tLoss: 0.381790\n",
      "Train Epoch 3 [30000/60000 (50%)]\tLoss: 0.331406\n",
      "Train Epoch 3 [32000/60000 (53%)]\tLoss: 0.278562\n",
      "Train Epoch 3 [34000/60000 (57%)]\tLoss: 0.127366\n",
      "Train Epoch 3 [36000/60000 (60%)]\tLoss: 0.381142\n",
      "Train Epoch 3 [38000/60000 (63%)]\tLoss: 0.234587\n",
      "Train Epoch 3 [40000/60000 (67%)]\tLoss: 0.089384\n",
      "Train Epoch 3 [42000/60000 (70%)]\tLoss: 0.206476\n",
      "Train Epoch 3 [44000/60000 (73%)]\tLoss: 0.277102\n",
      "Train Epoch 3 [46000/60000 (77%)]\tLoss: 0.260613\n",
      "Train Epoch 3 [48000/60000 (80%)]\tLoss: 0.340182\n",
      "Train Epoch 3 [50000/60000 (83%)]\tLoss: 0.178236\n",
      "Train Epoch 3 [52000/60000 (87%)]\tLoss: 0.327852\n",
      "Train Epoch 3 [54000/60000 (90%)]\tLoss: 0.199713\n",
      "Train Epoch 3 [56000/60000 (93%)]\tLoss: 0.182358\n",
      "Train Epoch 3 [58000/60000 (97%)]\tLoss: 0.347289\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch 4 [0/60000 (0%)]\tLoss: 0.238365\n",
      "Train Epoch 4 [2000/60000 (3%)]\tLoss: 0.261674\n",
      "Train Epoch 4 [4000/60000 (7%)]\tLoss: 0.205772\n",
      "Train Epoch 4 [6000/60000 (10%)]\tLoss: 0.322759\n",
      "Train Epoch 4 [8000/60000 (13%)]\tLoss: 0.320952\n",
      "Train Epoch 4 [10000/60000 (17%)]\tLoss: 0.203374\n",
      "Train Epoch 4 [12000/60000 (20%)]\tLoss: 0.221975\n",
      "Train Epoch 4 [14000/60000 (23%)]\tLoss: 0.141922\n",
      "Train Epoch 4 [16000/60000 (27%)]\tLoss: 0.368778\n",
      "Train Epoch 4 [18000/60000 (30%)]\tLoss: 0.215007\n",
      "Train Epoch 4 [20000/60000 (33%)]\tLoss: 0.227374\n",
      "Train Epoch 4 [22000/60000 (37%)]\tLoss: 0.161107\n",
      "Train Epoch 4 [24000/60000 (40%)]\tLoss: 0.197940\n",
      "Train Epoch 4 [26000/60000 (43%)]\tLoss: 0.187460\n",
      "Train Epoch 4 [28000/60000 (47%)]\tLoss: 0.122262\n",
      "Train Epoch 4 [30000/60000 (50%)]\tLoss: 0.207407\n",
      "Train Epoch 4 [32000/60000 (53%)]\tLoss: 0.272001\n",
      "Train Epoch 4 [34000/60000 (57%)]\tLoss: 0.301925\n",
      "Train Epoch 4 [36000/60000 (60%)]\tLoss: 0.206622\n",
      "Train Epoch 4 [38000/60000 (63%)]\tLoss: 0.187757\n",
      "Train Epoch 4 [40000/60000 (67%)]\tLoss: 0.211244\n",
      "Train Epoch 4 [42000/60000 (70%)]\tLoss: 0.208623\n",
      "Train Epoch 4 [44000/60000 (73%)]\tLoss: 0.247832\n",
      "Train Epoch 4 [46000/60000 (77%)]\tLoss: 0.092984\n",
      "Train Epoch 4 [48000/60000 (80%)]\tLoss: 0.236565\n",
      "Train Epoch 4 [50000/60000 (83%)]\tLoss: 0.157654\n",
      "Train Epoch 4 [52000/60000 (87%)]\tLoss: 0.169279\n",
      "Train Epoch 4 [54000/60000 (90%)]\tLoss: 0.140827\n",
      "Train Epoch 4 [56000/60000 (93%)]\tLoss: 0.240190\n",
      "Train Epoch 4 [58000/60000 (97%)]\tLoss: 0.122791\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch 5 [0/60000 (0%)]\tLoss: 0.110274\n",
      "Train Epoch 5 [2000/60000 (3%)]\tLoss: 0.227181\n",
      "Train Epoch 5 [4000/60000 (7%)]\tLoss: 0.167310\n",
      "Train Epoch 5 [6000/60000 (10%)]\tLoss: 0.122871\n",
      "Train Epoch 5 [8000/60000 (13%)]\tLoss: 0.207572\n",
      "Train Epoch 5 [10000/60000 (17%)]\tLoss: 0.164066\n",
      "Train Epoch 5 [12000/60000 (20%)]\tLoss: 0.275790\n",
      "Train Epoch 5 [14000/60000 (23%)]\tLoss: 0.160504\n",
      "Train Epoch 5 [16000/60000 (27%)]\tLoss: 0.167530\n",
      "Train Epoch 5 [18000/60000 (30%)]\tLoss: 0.234186\n",
      "Train Epoch 5 [20000/60000 (33%)]\tLoss: 0.215707\n",
      "Train Epoch 5 [22000/60000 (37%)]\tLoss: 0.221765\n",
      "Train Epoch 5 [24000/60000 (40%)]\tLoss: 0.189003\n",
      "Train Epoch 5 [26000/60000 (43%)]\tLoss: 0.225749\n",
      "Train Epoch 5 [28000/60000 (47%)]\tLoss: 0.354302\n",
      "Train Epoch 5 [30000/60000 (50%)]\tLoss: 0.179686\n",
      "Train Epoch 5 [32000/60000 (53%)]\tLoss: 0.132912\n",
      "Train Epoch 5 [34000/60000 (57%)]\tLoss: 0.147583\n",
      "Train Epoch 5 [36000/60000 (60%)]\tLoss: 0.113804\n",
      "Train Epoch 5 [38000/60000 (63%)]\tLoss: 0.252634\n",
      "Train Epoch 5 [40000/60000 (67%)]\tLoss: 0.173093\n",
      "Train Epoch 5 [42000/60000 (70%)]\tLoss: 0.210159\n",
      "Train Epoch 5 [44000/60000 (73%)]\tLoss: 0.225961\n",
      "Train Epoch 5 [46000/60000 (77%)]\tLoss: 0.224832\n",
      "Train Epoch 5 [48000/60000 (80%)]\tLoss: 0.253237\n",
      "Train Epoch 5 [50000/60000 (83%)]\tLoss: 0.136149\n",
      "Train Epoch 5 [52000/60000 (87%)]\tLoss: 0.139368\n",
      "Train Epoch 5 [54000/60000 (90%)]\tLoss: 0.236690\n",
      "Train Epoch 5 [56000/60000 (93%)]\tLoss: 0.213009\n",
      "Train Epoch 5 [58000/60000 (97%)]\tLoss: 0.246925\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9806/10000 (98%)\n",
      "\n",
      "Train Epoch 6 [0/60000 (0%)]\tLoss: 0.163913\n",
      "Train Epoch 6 [2000/60000 (3%)]\tLoss: 0.261954\n",
      "Train Epoch 6 [4000/60000 (7%)]\tLoss: 0.207261\n",
      "Train Epoch 6 [6000/60000 (10%)]\tLoss: 0.169901\n",
      "Train Epoch 6 [8000/60000 (13%)]\tLoss: 0.136062\n",
      "Train Epoch 6 [10000/60000 (17%)]\tLoss: 0.134837\n",
      "Train Epoch 6 [12000/60000 (20%)]\tLoss: 0.278432\n",
      "Train Epoch 6 [14000/60000 (23%)]\tLoss: 0.218403\n",
      "Train Epoch 6 [16000/60000 (27%)]\tLoss: 0.237423\n",
      "Train Epoch 6 [18000/60000 (30%)]\tLoss: 0.212918\n",
      "Train Epoch 6 [20000/60000 (33%)]\tLoss: 0.111729\n",
      "Train Epoch 6 [22000/60000 (37%)]\tLoss: 0.072642\n",
      "Train Epoch 6 [24000/60000 (40%)]\tLoss: 0.313018\n",
      "Train Epoch 6 [26000/60000 (43%)]\tLoss: 0.289408\n",
      "Train Epoch 6 [28000/60000 (47%)]\tLoss: 0.143148\n",
      "Train Epoch 6 [30000/60000 (50%)]\tLoss: 0.198381\n",
      "Train Epoch 6 [32000/60000 (53%)]\tLoss: 0.151958\n",
      "Train Epoch 6 [34000/60000 (57%)]\tLoss: 0.133757\n",
      "Train Epoch 6 [36000/60000 (60%)]\tLoss: 0.348249\n",
      "Train Epoch 6 [38000/60000 (63%)]\tLoss: 0.158748\n",
      "Train Epoch 6 [40000/60000 (67%)]\tLoss: 0.086329\n",
      "Train Epoch 6 [42000/60000 (70%)]\tLoss: 0.260032\n",
      "Train Epoch 6 [44000/60000 (73%)]\tLoss: 0.226534\n",
      "Train Epoch 6 [46000/60000 (77%)]\tLoss: 0.137746\n",
      "Train Epoch 6 [48000/60000 (80%)]\tLoss: 0.091459\n",
      "Train Epoch 6 [50000/60000 (83%)]\tLoss: 0.254322\n",
      "Train Epoch 6 [52000/60000 (87%)]\tLoss: 0.263710\n",
      "Train Epoch 6 [54000/60000 (90%)]\tLoss: 0.168352\n",
      "Train Epoch 6 [56000/60000 (93%)]\tLoss: 0.206123\n",
      "Train Epoch 6 [58000/60000 (97%)]\tLoss: 0.098023\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch 7 [0/60000 (0%)]\tLoss: 0.134304\n",
      "Train Epoch 7 [2000/60000 (3%)]\tLoss: 0.047600\n",
      "Train Epoch 7 [4000/60000 (7%)]\tLoss: 0.153244\n",
      "Train Epoch 7 [6000/60000 (10%)]\tLoss: 0.147100\n",
      "Train Epoch 7 [8000/60000 (13%)]\tLoss: 0.188834\n",
      "Train Epoch 7 [10000/60000 (17%)]\tLoss: 0.183435\n",
      "Train Epoch 7 [12000/60000 (20%)]\tLoss: 0.260110\n",
      "Train Epoch 7 [14000/60000 (23%)]\tLoss: 0.247666\n",
      "Train Epoch 7 [16000/60000 (27%)]\tLoss: 0.173705\n",
      "Train Epoch 7 [18000/60000 (30%)]\tLoss: 0.208961\n",
      "Train Epoch 7 [20000/60000 (33%)]\tLoss: 0.156770\n",
      "Train Epoch 7 [22000/60000 (37%)]\tLoss: 0.083206\n",
      "Train Epoch 7 [24000/60000 (40%)]\tLoss: 0.183506\n",
      "Train Epoch 7 [26000/60000 (43%)]\tLoss: 0.133671\n",
      "Train Epoch 7 [28000/60000 (47%)]\tLoss: 0.375053\n",
      "Train Epoch 7 [30000/60000 (50%)]\tLoss: 0.328063\n",
      "Train Epoch 7 [32000/60000 (53%)]\tLoss: 0.188245\n",
      "Train Epoch 7 [34000/60000 (57%)]\tLoss: 0.162060\n",
      "Train Epoch 7 [36000/60000 (60%)]\tLoss: 0.401499\n",
      "Train Epoch 7 [38000/60000 (63%)]\tLoss: 0.134109\n",
      "Train Epoch 7 [40000/60000 (67%)]\tLoss: 0.144968\n",
      "Train Epoch 7 [42000/60000 (70%)]\tLoss: 0.124171\n",
      "Train Epoch 7 [44000/60000 (73%)]\tLoss: 0.109255\n",
      "Train Epoch 7 [46000/60000 (77%)]\tLoss: 0.224128\n",
      "Train Epoch 7 [48000/60000 (80%)]\tLoss: 0.333750\n",
      "Train Epoch 7 [50000/60000 (83%)]\tLoss: 0.114402\n",
      "Train Epoch 7 [52000/60000 (87%)]\tLoss: 0.119094\n",
      "Train Epoch 7 [54000/60000 (90%)]\tLoss: 0.148253\n",
      "Train Epoch 7 [56000/60000 (93%)]\tLoss: 0.206634\n",
      "Train Epoch 7 [58000/60000 (97%)]\tLoss: 0.191779\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch 8 [0/60000 (0%)]\tLoss: 0.275824\n",
      "Train Epoch 8 [2000/60000 (3%)]\tLoss: 0.086651\n",
      "Train Epoch 8 [4000/60000 (7%)]\tLoss: 0.164738\n",
      "Train Epoch 8 [6000/60000 (10%)]\tLoss: 0.332732\n",
      "Train Epoch 8 [8000/60000 (13%)]\tLoss: 0.134714\n",
      "Train Epoch 8 [10000/60000 (17%)]\tLoss: 0.207527\n",
      "Train Epoch 8 [12000/60000 (20%)]\tLoss: 0.202910\n",
      "Train Epoch 8 [14000/60000 (23%)]\tLoss: 0.152877\n",
      "Train Epoch 8 [16000/60000 (27%)]\tLoss: 0.261284\n",
      "Train Epoch 8 [18000/60000 (30%)]\tLoss: 0.138865\n",
      "Train Epoch 8 [20000/60000 (33%)]\tLoss: 0.137469\n",
      "Train Epoch 8 [22000/60000 (37%)]\tLoss: 0.153077\n",
      "Train Epoch 8 [24000/60000 (40%)]\tLoss: 0.169004\n",
      "Train Epoch 8 [26000/60000 (43%)]\tLoss: 0.111884\n",
      "Train Epoch 8 [28000/60000 (47%)]\tLoss: 0.167081\n",
      "Train Epoch 8 [30000/60000 (50%)]\tLoss: 0.071808\n",
      "Train Epoch 8 [32000/60000 (53%)]\tLoss: 0.187541\n",
      "Train Epoch 8 [34000/60000 (57%)]\tLoss: 0.119582\n",
      "Train Epoch 8 [36000/60000 (60%)]\tLoss: 0.074141\n",
      "Train Epoch 8 [38000/60000 (63%)]\tLoss: 0.107321\n",
      "Train Epoch 8 [40000/60000 (67%)]\tLoss: 0.284877\n",
      "Train Epoch 8 [42000/60000 (70%)]\tLoss: 0.105805\n",
      "Train Epoch 8 [44000/60000 (73%)]\tLoss: 0.151129\n",
      "Train Epoch 8 [46000/60000 (77%)]\tLoss: 0.132288\n",
      "Train Epoch 8 [48000/60000 (80%)]\tLoss: 0.097427\n",
      "Train Epoch 8 [50000/60000 (83%)]\tLoss: 0.085336\n",
      "Train Epoch 8 [52000/60000 (87%)]\tLoss: 0.186321\n",
      "Train Epoch 8 [54000/60000 (90%)]\tLoss: 0.090642\n",
      "Train Epoch 8 [56000/60000 (93%)]\tLoss: 0.107598\n",
      "Train Epoch 8 [58000/60000 (97%)]\tLoss: 0.110788\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch 9 [0/60000 (0%)]\tLoss: 0.225337\n",
      "Train Epoch 9 [2000/60000 (3%)]\tLoss: 0.104166\n",
      "Train Epoch 9 [4000/60000 (7%)]\tLoss: 0.132663\n",
      "Train Epoch 9 [6000/60000 (10%)]\tLoss: 0.188423\n",
      "Train Epoch 9 [8000/60000 (13%)]\tLoss: 0.235943\n",
      "Train Epoch 9 [10000/60000 (17%)]\tLoss: 0.158807\n",
      "Train Epoch 9 [12000/60000 (20%)]\tLoss: 0.347893\n",
      "Train Epoch 9 [14000/60000 (23%)]\tLoss: 0.159437\n",
      "Train Epoch 9 [16000/60000 (27%)]\tLoss: 0.117783\n",
      "Train Epoch 9 [18000/60000 (30%)]\tLoss: 0.167979\n",
      "Train Epoch 9 [20000/60000 (33%)]\tLoss: 0.122061\n",
      "Train Epoch 9 [22000/60000 (37%)]\tLoss: 0.274984\n",
      "Train Epoch 9 [24000/60000 (40%)]\tLoss: 0.139209\n",
      "Train Epoch 9 [26000/60000 (43%)]\tLoss: 0.175828\n",
      "Train Epoch 9 [28000/60000 (47%)]\tLoss: 0.195642\n",
      "Train Epoch 9 [30000/60000 (50%)]\tLoss: 0.138495\n",
      "Train Epoch 9 [32000/60000 (53%)]\tLoss: 0.120635\n",
      "Train Epoch 9 [34000/60000 (57%)]\tLoss: 0.169122\n",
      "Train Epoch 9 [36000/60000 (60%)]\tLoss: 0.109406\n",
      "Train Epoch 9 [38000/60000 (63%)]\tLoss: 0.070186\n",
      "Train Epoch 9 [40000/60000 (67%)]\tLoss: 0.179328\n",
      "Train Epoch 9 [42000/60000 (70%)]\tLoss: 0.322386\n",
      "Train Epoch 9 [44000/60000 (73%)]\tLoss: 0.151766\n",
      "Train Epoch 9 [46000/60000 (77%)]\tLoss: 0.125708\n",
      "Train Epoch 9 [48000/60000 (80%)]\tLoss: 0.127507\n",
      "Train Epoch 9 [50000/60000 (83%)]\tLoss: 0.092694\n",
      "Train Epoch 9 [52000/60000 (87%)]\tLoss: 0.136464\n",
      "Train Epoch 9 [54000/60000 (90%)]\tLoss: 0.112986\n",
      "Train Epoch 9 [56000/60000 (93%)]\tLoss: 0.160500\n",
      "Train Epoch 9 [58000/60000 (97%)]\tLoss: 0.032687\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch 10 [0/60000 (0%)]\tLoss: 0.120366\n",
      "Train Epoch 10 [2000/60000 (3%)]\tLoss: 0.085876\n",
      "Train Epoch 10 [4000/60000 (7%)]\tLoss: 0.165382\n",
      "Train Epoch 10 [6000/60000 (10%)]\tLoss: 0.194718\n",
      "Train Epoch 10 [8000/60000 (13%)]\tLoss: 0.172671\n",
      "Train Epoch 10 [10000/60000 (17%)]\tLoss: 0.180549\n",
      "Train Epoch 10 [12000/60000 (20%)]\tLoss: 0.282817\n",
      "Train Epoch 10 [14000/60000 (23%)]\tLoss: 0.198011\n",
      "Train Epoch 10 [16000/60000 (27%)]\tLoss: 0.126930\n",
      "Train Epoch 10 [18000/60000 (30%)]\tLoss: 0.135714\n",
      "Train Epoch 10 [20000/60000 (33%)]\tLoss: 0.183785\n",
      "Train Epoch 10 [22000/60000 (37%)]\tLoss: 0.277387\n",
      "Train Epoch 10 [24000/60000 (40%)]\tLoss: 0.093542\n",
      "Train Epoch 10 [26000/60000 (43%)]\tLoss: 0.121826\n",
      "Train Epoch 10 [28000/60000 (47%)]\tLoss: 0.205519\n",
      "Train Epoch 10 [30000/60000 (50%)]\tLoss: 0.094396\n",
      "Train Epoch 10 [32000/60000 (53%)]\tLoss: 0.295096\n",
      "Train Epoch 10 [34000/60000 (57%)]\tLoss: 0.100597\n",
      "Train Epoch 10 [36000/60000 (60%)]\tLoss: 0.111471\n",
      "Train Epoch 10 [38000/60000 (63%)]\tLoss: 0.114555\n",
      "Train Epoch 10 [40000/60000 (67%)]\tLoss: 0.121445\n",
      "Train Epoch 10 [42000/60000 (70%)]\tLoss: 0.187426\n",
      "Train Epoch 10 [44000/60000 (73%)]\tLoss: 0.224860\n",
      "Train Epoch 10 [46000/60000 (77%)]\tLoss: 0.129632\n",
      "Train Epoch 10 [48000/60000 (80%)]\tLoss: 0.205609\n",
      "Train Epoch 10 [50000/60000 (83%)]\tLoss: 0.105561\n",
      "Train Epoch 10 [52000/60000 (87%)]\tLoss: 0.127918\n",
      "Train Epoch 10 [54000/60000 (90%)]\tLoss: 0.098772\n",
      "Train Epoch 10 [56000/60000 (93%)]\tLoss: 0.124578\n",
      "Train Epoch 10 [58000/60000 (97%)]\tLoss: 0.180384\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9864/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)  \n",
    "    test()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1e0d61-6c59-4118-ac5e-e0629f5e0eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6b92c08-08fd-4b5a-b8c4-556a4294c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.train()\n",
    "\n",
    "data, target = test_data[56]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"prediction: {prediction}\")\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap=\"Reds\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbfc9977-0d65-4f83-87b4-f84047080b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n",
      "Actual: 7\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data, target = test_data[0]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "    pred = output.argmax(1).item()\n",
    "\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Actual:\", target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c48d7725-4451-45a7-9fe1-80616c845683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import PIL.ImageOps\n",
    "from PIL import Image\n",
    "\n",
    "# Also make sure your 'device' is defined for the .to(device) part\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13fa4090-f8a9-4f45-8737-00f698e442b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_my_digit(image_path, model):\n",
    "    # 1. Load the image and convert to Grayscale ('L')\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    \n",
    "    # 2. Invert colors (MNIST is white ink on black background)\n",
    "    img = PIL.ImageOps.invert(img)\n",
    "    \n",
    "    # 3. Resize to exactly 28x28 pixels\n",
    "    img = img.resize((28, 28))\n",
    "    \n",
    "    # 4. Convert to Tensor and Normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device) # Add batch dimension (1, 1, 28, 28)\n",
    "\n",
    "    # 5. Predict!\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dc747c3-efd0-4e97-a9e4-a41e5e1a23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model thinks you wrote a: 4\n"
     ]
    }
   ],
   "source": [
    "result = predict_my_digit('my_digit1.png', model)\n",
    "print(f\"The model thinks you wrote a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2422324a-34fa-4bc5-9168-887fc1379114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model thinks you wrote a: 8\n"
     ]
    }
   ],
   "source": [
    "result = predict_my_digit('my_digit2.png', model)\n",
    "print(f\"The model thinks you wrote a: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7a772-e597-4966-896b-29ac237d2e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (torch_gpu)",
   "language": "python",
   "name": "torch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
